=encoding utf8

=head1 NAME

OpenAPI::Client::OpenAI::Path::chat-completions - Documentation for the /chat/completions path.

=head1 DESCRIPTION

This document describes the API endpoint at C</chat/completions>.

=head1 PATHS


=head2 C<GET /chat/completions>

List Chat Completions


List stored Chat Completions. Only Chat Completions that have been stored
with the C<store> parameter set to C<true> will be returned.



=head3 Operation ID

C<listChatCompletions>

    $client->listChatCompletions( ... );

=head3 Parameters

=over 4

=item * C<model> (in query) (Optional) - The model used to generate the Chat Completions.

Type: C<string>



=item * C<metadata> (in query) (Optional) - A list of metadata keys to filter the Chat Completions by. Example:

`metadata[key1]=value1&metadata[key2]=value2`


Type: C<object>



=item * C<after> (in query) (Optional) - Identifier for the last chat completion from the previous pagination request.

Type: C<string>



=item * C<limit> (in query) (Optional) - Number of Chat Completions to retrieve.

Type: C<integer>


Default: C<20>


=item * C<order> (in query) (Optional) - Sort order for Chat Completions by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

Type: C<string>

Allowed values: C<asc, desc>


Default: C<asc>


=back


=head3 Responses


=head4 Status Code: C<200>

A list of Chat Completions


=head4 Content Types:

=over 4


=item * C<application/json>

Example (See the L<OpenAI spec for more detail|https://github.com/openai/openai-openapi/blob/master/openapi.yaml>):

    {
      "object": "list",
      "data": [
        {
          "object": "chat.completion",
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
          "model": "gpt-4o-2024-08-06",
          "created": 1738960610,
          "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
          "tool_choice": null,
          "usage": {
            "total_tokens": 31,
            "completion_tokens": 18,
            "prompt_tokens": 13
          },
          "seed": 4944116822809979520,
          "top_p": 1.0,
          "temperature": 1.0,
          "presence_penalty": 0.0,
          "frequency_penalty": 0.0,
          "system_fingerprint": "fp_50cad350e4",
          "input_user": null,
          "service_tier": "default",
          "tools": null,
          "metadata": {},
          "choices": [
            {
              "index": 0,
              "message": {
                "content": "Mind of circuits hum,  \nLearning patterns in silenceâ€”  \nFuture's quiet spark.",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
              },
              "finish_reason": "stop",
              "logprobs": null
            }
          ],
          "response_format": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "has_more": false
    }


=back

=head2 C<POST /chat/completions>

Create chat completion


B<Starting a new project?> We recommend trying L<Responses|https://platform.openai.com/docs/api-reference/responses> 
to take advantage of the latest OpenAI platform features. Compare
L<Chat Completions with Responses|https://platform.openai.com/docs/guides/responses-vs-chat-completions?api-mode=responses>.

================================================================================
Creates a model response for the given chat conversation. Learn more in the
L<text generation|https://platform.openai.com/docs/guides/text-generation>, L<vision|https://platform.openai.com/docs/guides/vision>,
and L<audio|https://platform.openai.com/docs/guides/audio> guides.

Parameter support can differ depending on the model used to generate the
response, particularly for newer reasoning models. Parameters that are only
supported for reasoning models are noted below. For the current state of 
unsupported parameters in reasoning models, 
L<refer to the reasoning guide|https://platform.openai.com/docs/guides/reasoning>.



=head3 Operation ID

C<createChatCompletion>

    $client->createChatCompletion( ... );

=head3 Parameters

=over 4

=back

=head3 Request Body
  
=head3 Content Type: C<application/json>

    
      

      
             

=head3 Responses


=head4 Status Code: C<200>

OK


=head4 Content Types:

=over 4


=item * C<application/json>

Example (See the L<OpenAI spec for more detail|https://github.com/openai/openai-openapi/blob/master/openapi.yaml>):

    {
      "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
      "object": "chat.completion",
      "created": 1741570283,
      "model": "gpt-4o-2024-08-06",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
            "refusal": null,
            "annotations": []
          },
          "logprobs": null,
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 1117,
        "completion_tokens": 46,
        "total_tokens": 1163,
        "prompt_tokens_details": {
          "cached_tokens": 0,
          "audio_tokens": 0
        },
        "completion_tokens_details": {
          "reasoning_tokens": 0,
          "audio_tokens": 0,
          "accepted_prediction_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "service_tier": "default",
      "system_fingerprint": "fp_fc9f1d7035"
    }



=item * C<text/event-stream>

Example (See the L<OpenAI spec for more detail|https://github.com/openai/openai-openapi/blob/master/openapi.yaml>):

    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}
    
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}
    
    ....
    
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


=back

=head1 SEE ALSO

L<OpenAPI::Client::OpenAI::Path>

=head1 COPYRIGHT AND LICENSE

Copyright (C) 2023-2025 by Nelson Ferraz

This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.14.0 or,
at your option, any later version of Perl 5 you may have available.

=cut